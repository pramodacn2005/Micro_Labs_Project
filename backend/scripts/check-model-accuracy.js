/**
 * Quick script to check model accuracy from saved metrics
 * Run with: node backend/scripts/check-model-accuracy.js
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const metricsPath = path.resolve(__dirname, "..", "models", "fever_model_metrics.json");

function checkAccuracy() {
  console.log("=".repeat(60));
  console.log("ğŸ¯ FEVER MODEL ACCURACY CHECK");
  console.log("=".repeat(60));

  if (!fs.existsSync(metricsPath)) {
    console.log("\nâŒ Metrics file not found!");
    console.log(`   Expected at: ${metricsPath}`);
    console.log("\nğŸ’¡ The model will be trained automatically on first use.");
    console.log("   After training, metrics will be saved here.");
    return;
  }

  try {
    const metricsData = JSON.parse(fs.readFileSync(metricsPath, "utf8"));

    console.log("\nğŸ“ Model Information:");
    console.log(`   Trained at: ${metricsData.trained_at || "Unknown"}`);
    if (metricsData.dataset) {
      const datasetName = path.basename(metricsData.dataset);
      console.log(`   Dataset: ${datasetName}`);
    }

    if (metricsData.metrics) {
      const m = metricsData.metrics;
      console.log("\nğŸ“ˆ Model Performance Metrics:");
      console.log("   (Based on 5-fold cross-validation during training)");
      console.log("\n" + "â”€".repeat(60));
      console.log(`   âœ… Accuracy:  ${(m.accuracy * 100).toFixed(2)}%`);
      console.log(`   ğŸ“Š Precision: ${(m.precision * 100).toFixed(2)}% (macro average)`);
      console.log(`   ğŸ” Recall:    ${(m.recall * 100).toFixed(2)}% (macro average)`);
      console.log(`   âš–ï¸  F1-Score:  ${(m.f1 * 100).toFixed(2)}% (macro average)`);
      if (m.roc_auc) {
        console.log(`   ğŸ“ˆ ROC-AUC:   ${(m.roc_auc * 100).toFixed(2)}%`);
      }
      console.log("â”€".repeat(60));

      // Interpretation
      console.log("\nğŸ’¡ Interpretation:");
      const accuracy = m.accuracy;
      if (accuracy >= 0.95) {
        console.log("   ğŸŸ¢ Excellent! Model has very high accuracy");
      } else if (accuracy >= 0.85) {
        console.log("   ğŸŸ¡ Good accuracy, but could be improved");
      } else if (accuracy >= 0.70) {
        console.log("   ğŸŸ  Moderate accuracy, consider retraining with more data");
      } else {
        console.log("   ğŸ”´ Low accuracy, model needs improvement");
      }

      console.log("\nğŸ“ Note: These are cross-validation metrics from training.");
      console.log("   For a more detailed evaluation on a test set, run:");
      console.log("   python ml/scripts/evaluate_model_accuracy.py");
    } else {
      console.log("\nâš ï¸  No metrics found in the file");
    }
  } catch (error) {
    console.error("\nâŒ Error reading metrics file:", error.message);
  }

  console.log("\n" + "=".repeat(60));
}

checkAccuracy();











